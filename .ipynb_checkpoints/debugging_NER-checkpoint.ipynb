{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3e95669-e0f3-4713-89ad-4cf797fede1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random, ast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from itertools import combinations\n",
    "from scipy import stats\n",
    "from torch import Tensor\n",
    "\n",
    "import configuration\n",
    "from dataset_class.data_preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e23b4bf5-17bf-4543-8541-920fec1613cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Configuration for NER Pipeline \"\"\"\n",
    "\n",
    "class CFG:\n",
    "    \"\"\" Pipeline Setting \"\"\"\n",
    "    train, test = True, False\n",
    "    checkpoint_dir = './saved/model'\n",
    "    resume, load_pretrained,  state_dict = True, False, '/'\n",
    "    name = 'FBP3_Base_Train_Pipeline'\n",
    "    loop = 'mpl_loop'\n",
    "    dataset = 'FBPDataset'  # dataset_class.dataclass.py -> FBPDataset, MPLDataset\n",
    "    model_arch = 'FBPModel'  # model.model.py -> FBPModel, MPLModel\n",
    "    model = 'microsoft/deberta-v3-large'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    pooling = 'MeanPooling'  # mean, attention, max, weightedlayer, concat, conv1d, lstm\n",
    "\n",
    "    \"\"\" Common Options \"\"\"\n",
    "    wandb = True\n",
    "    optuna = False  # if you want to tune hyperparameter, set True\n",
    "    competition = 'FB3'\n",
    "    seed = 42\n",
    "    cfg_name = 'CFG'\n",
    "    n_gpu = 1\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps')\n",
    "    gpu_id = 0\n",
    "    num_workers = 0\n",
    "\n",
    "    \"\"\" Data Options \"\"\"\n",
    "    n_folds = 5\n",
    "    max_len = 2048  # Max Sequence Length == 1778\n",
    "    epochs = 180\n",
    "    batch_size = 64\n",
    "    val_batch_size = 64\n",
    "\n",
    "    \"\"\" Gradient Options \"\"\"\n",
    "    amp_scaler = False\n",
    "    gradient_checkpoint = True  # save parameter\n",
    "    clipping_grad = True  # clip_grad_norm\n",
    "    n_gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "\n",
    "    \"\"\" Loss & Metrics Options \"\"\"\n",
    "    loss_fn = 'SmoothL1Loss'\n",
    "    # val_loss_fn = 'WeightedMSELoss'\n",
    "    margin = 0.5\n",
    "    reduction = 'mean'\n",
    "    metrics = ['MCRMSE', 'f_beta', 'recall']\n",
    "\n",
    "    \"\"\" Optimizer with LLRD Options \"\"\"\n",
    "    optimizer = 'AdamW'  # options: SWA, AdamW\n",
    "    llrd = True\n",
    "    layerwise_lr = 5e-6\n",
    "    layerwise_lr_decay = 0.9\n",
    "    layerwise_weight_decay = 1e-2\n",
    "    layerwise_adam_epsilon = 1e-6\n",
    "    layerwise_use_bertadam = False\n",
    "    betas = (0.9, 0.999)\n",
    "\n",
    "    \"\"\" Scheduler Options \"\"\"\n",
    "    scheduler = 'cosine_annealing'  # options: cosine, linear, cosine_annealing, linear_annealing\n",
    "    batch_scheduler = True\n",
    "    num_cycles = 0.5  # num_warmup_steps = 0\n",
    "    warmup_ratio = 0.1  # options: 0.05, 0.1\n",
    "\n",
    "    \"\"\" SWA Options \"\"\"\n",
    "    swa = True\n",
    "    swa_start = int(epochs*0.75)\n",
    "    swa_lr = 1e-4\n",
    "    anneal_epochs = 4\n",
    "    anneal_strategy = 'cos'  # default = cos, available option: linear\n",
    "\n",
    "    \"\"\" Model_Utils Options \"\"\"\n",
    "    init_weight = 'xavier_normal'\n",
    "    stop_mode = 'min'\n",
    "    freeze = False\n",
    "    num_freeze = 2\n",
    "    reinit = True\n",
    "    num_reinit = 0\n",
    "    awp = False\n",
    "    nth_awp_start_epoch = 10\n",
    "    awp_eps = 1e-2\n",
    "    awp_lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4b2aa58f-70f6-4b2e-b42e-db5b0e0022c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_device() -> bool:\n",
    "    return torch.mps.is_available()\n",
    "\n",
    "def check_library(checker: bool) -> tuple:\n",
    "    \"\"\"\n",
    "    1) checker == True\n",
    "        - current device is mps\n",
    "    2) checker == False\n",
    "        - current device is cuda with cudnn\n",
    "    \"\"\"\n",
    "    if not checker:\n",
    "        _is_built = torch.backends.cudnn.is_available()\n",
    "        _is_enable = torch.backends.cudnn.enabledtorch.backends.cudnn.enabled\n",
    "        version = torch.backends.cudnn.version()\n",
    "        device = (_is_built, _is_enable, version)\n",
    "        return device\n",
    "\n",
    "\n",
    "def class2dict(cfg) -> dict:\n",
    "    return dict((name, getattr(cfg, name)) for name in dir(cfg) if not name.startswith('__'))\n",
    "\n",
    "\n",
    "def all_type_seed(cfg, checker: bool) -> None:\n",
    "    # python & torch seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(cfg.seed)  # python Seed\n",
    "    random.seed(cfg.seed)  # random module Seed\n",
    "    np.random.seed(cfg.seed)  # numpy module Seed\n",
    "    torch.manual_seed(cfg.seed)  # Pytorch CPU Random Seed Maker\n",
    "\n",
    "    # device == cuda\n",
    "    if not checker:\n",
    "        torch.cuda.manual_seed(cfg.seed)  # Pytorch GPU Random Seed Maker\n",
    "        torch.cuda.manual_seed_all(cfg.seed)  # Pytorch Multi Core GPU Random Seed Maker\n",
    "        # torch.cudnn seed\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.enabled = True\n",
    "\n",
    "    # devide == mps\n",
    "    else:\n",
    "        torch.mps.manual_seed(cfg.seed)\n",
    "\n",
    "\n",
    "def seed_worker(worker_id) -> None:\n",
    "    worker_seed = torch.initial_seed() % 2 ** 32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = \"false\"\n",
    "os.environ['LRU_CACHE_CAPACITY'] = \"1\"\n",
    "os.environ['AUTOCASTLONGTO_FLOAT16'] = \"false\"\n",
    "check_library(True)\n",
    "all_type_seed(CFG, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c73c93b0-4e9a-4085-a981-114aa5e88020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E1FA876D6E6C</td>\n",
       "      <td>Dear Senator,\\n\\nI am writting this letter to ...</td>\n",
       "      <td>['O', 'O', 'B-Lead', 'I-Lead', 'I-Lead', 'I-Le...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8AC1D6E165CD</td>\n",
       "      <td>Dear Principal, I believe in policy 2. Kids ar...</td>\n",
       "      <td>['O', 'O', 'B-Position', 'I-Position', 'I-Posi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45EF6A4EDB1A</td>\n",
       "      <td>Summer projects are no fun, but they are a gre...</td>\n",
       "      <td>['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0070361406D</td>\n",
       "      <td>The author who wrote \"The challenge of Explori...</td>\n",
       "      <td>['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>839F4F7F7DD7</td>\n",
       "      <td>Our school systems have seen many changes as t...</td>\n",
       "      <td>['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15589</th>\n",
       "      <td>DB0E754610DB</td>\n",
       "      <td>In my opinion I think that the author did a gr...</td>\n",
       "      <td>['B-Position', 'I-Position', 'I-Position', 'I-...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15590</th>\n",
       "      <td>709156BCF733</td>\n",
       "      <td>Dear Principal:\\n\\nI think students must have ...</td>\n",
       "      <td>['O', 'O', 'B-Position', 'I-Position', 'I-Posi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15591</th>\n",
       "      <td>A0F328ADB40C</td>\n",
       "      <td>I believe that students should not be allowed ...</td>\n",
       "      <td>['B-Position', 'I-Position', 'I-Position', 'I-...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15592</th>\n",
       "      <td>688370E9E6F1</td>\n",
       "      <td>i think that technology is valuable because yo...</td>\n",
       "      <td>['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15593</th>\n",
       "      <td>796911DBD5C2</td>\n",
       "      <td>Do you ever get tired of having to wake up so ...</td>\n",
       "      <td>['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15594 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                               text  \\\n",
       "0      E1FA876D6E6C  Dear Senator,\\n\\nI am writting this letter to ...   \n",
       "1      8AC1D6E165CD  Dear Principal, I believe in policy 2. Kids ar...   \n",
       "2      45EF6A4EDB1A  Summer projects are no fun, but they are a gre...   \n",
       "3      B0070361406D  The author who wrote \"The challenge of Explori...   \n",
       "4      839F4F7F7DD7  Our school systems have seen many changes as t...   \n",
       "...             ...                                                ...   \n",
       "15589  DB0E754610DB  In my opinion I think that the author did a gr...   \n",
       "15590  709156BCF733  Dear Principal:\\n\\nI think students must have ...   \n",
       "15591  A0F328ADB40C  I believe that students should not be allowed ...   \n",
       "15592  688370E9E6F1  i think that technology is valuable because yo...   \n",
       "15593  796911DBD5C2  Do you ever get tired of having to wake up so ...   \n",
       "\n",
       "                                                entities  fold  \n",
       "0      ['O', 'O', 'B-Lead', 'I-Lead', 'I-Lead', 'I-Le...     0  \n",
       "1      ['O', 'O', 'B-Position', 'I-Position', 'I-Posi...     4  \n",
       "2      ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...     3  \n",
       "3      ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...     0  \n",
       "4      ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...     4  \n",
       "...                                                  ...   ...  \n",
       "15589  ['B-Position', 'I-Position', 'I-Position', 'I-...     2  \n",
       "15590  ['O', 'O', 'B-Position', 'I-Position', 'I-Posi...     2  \n",
       "15591  ['B-Position', 'I-Position', 'I-Position', 'I-...     4  \n",
       "15592  ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...     0  \n",
       "15593  ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...     2  \n",
       "\n",
       "[15594 rows x 4 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Load Train Dataset \"\"\"\n",
    "train_df = pd.read_csv('./dataset_class/data_folder/final_converted_train_df.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "afa7c0bd-e367-4776-afd0-1685082cc33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc95291a9504b6188eff650cf309cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1778"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Max Sequence Length: 1778 for after tokenizing \"\"\"\n",
    "length_list = sequence_length(CFG, train_df.text.to_list())\n",
    "max(length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "60ffcaf4-46d0-45cd-a8d3-fc8db018fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Data utils \"\"\"\n",
    "\n",
    "def sequence_length(cfg: configuration.CFG, text_list: list) -> list:\n",
    "    \"\"\" Get sequence length of all text data for checking statistics value \"\"\"\n",
    "    length_list = []\n",
    "    for text in tqdm(text_list):\n",
    "        tmp_text = ner_tokenizing(cfg, text)['attention_mask']\n",
    "        length_list.append(tmp_text.count(1))\n",
    "    return length_list\n",
    "\n",
    "def check_null(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\" check if input dataframe has null type object...etc \"\"\"\n",
    "    return df.isnull().sum()\n",
    "\n",
    "def kfold(df: pd.DataFrame, cfg) -> pd.DataFrame:\n",
    "    \"\"\" KFold \"\"\"\n",
    "    fold = KFold(\n",
    "        n_splits=cfg.n_folds,\n",
    "        shuffle=True,\n",
    "        random_state=cfg.seed\n",
    "    )\n",
    "    df['fold'] = -1\n",
    "    for num, (tx, vx) in enumerate(fold.split(df)):\n",
    "        df.loc[vx, \"fold\"] = int(num)\n",
    "    return df\n",
    "\n",
    "def group_kfold(df: pd.DataFrame, cfg: configuration.CFG) -> pd.DataFrame:\n",
    "    \"\"\" GroupKFold \"\"\"\n",
    "    fold = GroupKFold(\n",
    "        n_splits=cfg.n_folds,\n",
    "    )\n",
    "    df['fold'] = -1\n",
    "    for num, (tx, vx) in enumerate(fold.split(X=df, y=df['pct_rank'], groups=df['ancestor_id'])):\n",
    "        df.loc[vx, \"fold\"] = int(num)\n",
    "    return df\n",
    "\n",
    "def ner_tokenizing(cfg: configuration.CFG, text: str):\n",
    "    \"\"\"\n",
    "    Preprocess text for NER Pipeline\n",
    "    if you want to set param 'return_offsets_mapping' == True, you must use FastTokenizer\n",
    "    you must use PretrainedTokenizer which is supported FastTokenizer\n",
    "    Converting text to torch.Tensor will be done in Custom Dataset Class\n",
    "    Params:\n",
    "        return_offsets_mapping:\n",
    "            - (bool, optional, defaults to False)\n",
    "            - Whether or not to return (char_start, char_end) for each token.\n",
    "            => useful for NER Task\n",
    "    Args:\n",
    "        cfg: configuration.CFG, needed to load tokenizer from Huggingface AutoTokenizer\n",
    "        text: text from dataframe or any other dataset, please pass str type\n",
    "    \"\"\"\n",
    "    inputs = cfg.tokenizer(\n",
    "        text,\n",
    "        return_offsets_mapping=True,  # only available for FastTokenizer by Rust, not erase /n, /n/n\n",
    "        max_length=cfg.max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors=None,\n",
    "        add_special_tokens=True,\n",
    "    )\n",
    "    return inputs\n",
    "\n",
    "def load_data(data_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load data_folder from csv file like as train.csv, test.csv, val.csv\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df\n",
    "\n",
    "def labels2ids():\n",
    "    \"\"\"\n",
    "    Encoding labels to ids for neural network with BIO Styles\n",
    "    labels2dict = {\n",
    "    'O': 0, 'B-Lead': 1, 'I-Lead': 2, 'B-Position': 3, 'I-Position': 4, 'B-Claim': 5,\n",
    "    'I-Claim': 6, 'B-Counterclaim': 7, 'I-Counterclaim': 8, 'B-Rebuttal': 9, 'I-Rebuttal': 10,\n",
    "    'B-Evidence': 11, 'I-Evidence': 12, 'B-Concluding Statement': 13, 'I-Concluding Statement': 14\n",
    "     }\n",
    "    \"\"\"\n",
    "    output_labels = [\n",
    "        'O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim',\n",
    "        'I-Counterclaim', 'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement',\n",
    "        'I-Concluding Statement'\n",
    "    ]\n",
    "    labels_to_ids = {v: k for k, v in enumerate(output_labels)}\n",
    "    return labels_to_ids\n",
    "\n",
    "\n",
    "def ids2labels():\n",
    "    \"\"\"\n",
    "    Decoding labels to ids for neural network with BIO Styles\n",
    "    labels2dict = {\n",
    "    'O': 0, 'B-Lead': 1, 'I-Lead': 2, 'B-Position': 3, 'I-Position': 4, 'B-Claim': 5,\n",
    "    'I-Claim': 6, 'B-Counterclaim': 7, 'I-Counterclaim': 8, 'B-Rebuttal': 9, 'I-Rebuttal': 10,\n",
    "    'B-Evidence': 11, 'I-Evidence': 12, 'B-Concluding Statement': 13, 'I-Concluding Statement': 14\n",
    "     }\n",
    "\n",
    "    \"\"\"\n",
    "    output_labels = [\n",
    "        'O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim',\n",
    "        'I-Counterclaim', 'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement',\n",
    "        'I-Concluding Statement'\n",
    "    ]\n",
    "    ids_to_labels = {k: v for k, v in enumerate(output_labels)}\n",
    "    return ids_to_labels\n",
    "\n",
    "def split_mapping(unsplit):\n",
    "    \"\"\" Return array which is mapping character index to index of word in list of split() words \"\"\"\n",
    "    splt = unsplit.split()\n",
    "    offset_to_wordidx = np.full(len(unsplit),-1)\n",
    "    txt_ptr = 0\n",
    "    for split_index, full_word in enumerate(splt):\n",
    "        while unsplit[txt_ptr:txt_ptr + len(full_word)] != full_word:\n",
    "            txt_ptr += 1\n",
    "        offset_to_wordidx[txt_ptr:txt_ptr + len(full_word)] = split_index\n",
    "        txt_ptr += len(full_word)\n",
    "    return offset_to_wordidx\n",
    "\n",
    "def sorted_quantile(array: list, q: float):\n",
    "    \"\"\"\n",
    "    This is used to prevent re-sorting to compute quantile for every sequence.\n",
    "    Args:\n",
    "        array: list of element\n",
    "        q: accumulate probability which you want to calculate spot\n",
    "    Reference:\n",
    "        https://stackoverflow.com/questions/60467081/linear-interpolation-in-numpy-quantile\n",
    "        https://www.kaggle.com/code/chasembowers/sequence-postprocessing-v2-67-lb/notebook\n",
    "    \"\"\"\n",
    "    array = np.array(array)\n",
    "    n = len(array)\n",
    "    index = (n - 1) * q\n",
    "    left = np.floor(index).astype(int)\n",
    "    fraction = index - left\n",
    "    right = left\n",
    "    right = right + (fraction > 0).astype(int)\n",
    "    i, j = array[left], array[right]\n",
    "    return i + (j - i) * fraction\n",
    "\n",
    "labels2ids = labels2ids()\n",
    "ids2labels = ids2labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0c2151a7-569a-47dd-b734-197ea3ac1353",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model Utils \"\"\"\n",
    "def freeze(module) -> None:\n",
    "    \"\"\"\n",
    "    Freezes module's parameters.\n",
    "\n",
    "    [Example]\n",
    "    freezing embeddings and first 2 layers of encoder\n",
    "    1) freeze(model.embeddings)\n",
    "    2) freeze(model.encoder.layer[:2])\n",
    "    \"\"\"\n",
    "    for parameter in module.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "def reinit_topk(model, num_layers):\n",
    "    \"\"\"\n",
    "    Re-initialize the last-k transformer Encoder layers.\n",
    "    Encoder Layer: Embedding, Attention Head, LayerNorm, Feed Forward\n",
    "    Args:\n",
    "        model: The target transformer model.\n",
    "        num_layers: The number of layers to be re-initialized.\n",
    "    \"\"\"\n",
    "    if num_layers > 0:\n",
    "        model.encoder.layers[-num_layers:].apply(model._init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d5e2c183-d212-402f-a6ef-9a71502b089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Trainer Utils \"\"\"\n",
    "def get_optimizer_grouped_parameters(model, layerwise_lr, layerwise_weight_decay, layerwise_lr_decay):\n",
    "    \"\"\" Grouped Version: Layer-wise learning rate decay \"\"\"\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    # initialize lr for task specific layer\n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "                                     \"weight_decay\": 0.0,\n",
    "                                     \"lr\": layerwise_lr,\n",
    "                                     }, ]\n",
    "    # initialize lrs for every layer\n",
    "    layers = [model.embeddings] + list(model.encoder.layers)\n",
    "    layers.reverse()\n",
    "    lr = layerwise_lr\n",
    "    for layer in layers:\n",
    "        optimizer_grouped_parameters += [\n",
    "            {\"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             \"weight_decay\": layerwise_weight_decay,\n",
    "             \"lr\": lr,\n",
    "             },\n",
    "            {\"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             \"weight_decay\": 0.0,\n",
    "             \"lr\": lr,\n",
    "             },]\n",
    "        lr *= layerwise_lr_decay\n",
    "    return optimizer_grouped_parameters\n",
    "\n",
    "def collate(inputs):\n",
    "    \"\"\" Descending sort inputs by length of sequence \"\"\"\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:, :mask_len]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def get_swa_scheduler(cfg, optimizer):\n",
    "    \"\"\"  SWA Scheduler \"\"\"\n",
    "    swa_scheduler = getattr(torch.optim.swa_utils, 'SWALR')(\n",
    "        optimizer,\n",
    "        swa_lr=cfg.swa_lr,\n",
    "        anneal_epochs=cfg.anneal_epochs,\n",
    "        anneal_strategy=cfg.anneal_strategy\n",
    "    )\n",
    "    return swa_scheduler\n",
    "\n",
    "\n",
    "def get_scheduler(cfg, optimizer, len_train: int):\n",
    "    \"\"\" Select Scheduler Function \"\"\"\n",
    "    scheduler_dict = {\n",
    "        'cosine_annealing': 'get_cosine_with_hard_restarts_schedule_with_warmup',\n",
    "        'cosine': 'get_cosine_schedule_with_warmup',\n",
    "        'linear': 'get_linear_schedule_with_warmup'\n",
    "    }\n",
    "    lr_scheduler = getattr(transformers, scheduler_dict[cfg.scheduler])(\n",
    "        optimizer,\n",
    "        num_warmup_steps=int(len_train/cfg.batch_size * cfg.epochs/cfg.n_gradient_accumulation_steps) * cfg.warmup_ratio,\n",
    "        num_training_steps=int(len_train/cfg.batch_size * cfg.epochs/cfg.n_gradient_accumulation_steps),\n",
    "        num_cycles=cfg.num_cycles\n",
    "    )\n",
    "    return lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e4e206e9-2ffe-461b-a60f-4a80747356ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Loss & Metric Function \"\"\"\n",
    "\n",
    "class SmoothL1Loss(nn.Module):\n",
    "    \"\"\" Smooth L1 Loss in Pytorch \"\"\"\n",
    "    def __init__(self, reduction):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, y_pred, y_true) -> Tensor:\n",
    "        criterion = nn.SmoothL1Loss(reduction=self.reduction)\n",
    "        return criterion(y_pred, y_true)\n",
    "\n",
    "\n",
    "# Cross-Entropy Loss\n",
    "class CrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, reduction):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, y_pred, y_true) -> Tensor:\n",
    "        criterion = nn.CrossEntropyLoss(reduction=self.reduction)\n",
    "        return criterion(y_pred, y_true)\n",
    "\n",
    "\n",
    "# Binary Cross-Entropy Loss\n",
    "class BinaryCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, reduction):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, y_pred, y_true) -> Tensor:\n",
    "        criterion = nn.BCEWithLogitsLoss(reduction=self.reduction)\n",
    "        return criterion(y_pred, y_true)\n",
    "\n",
    "def recall(y_true, y_pred) -> float:\n",
    "    \"\"\"\n",
    "    Actual positives that the model predicted to be positive\n",
    "    Math:\n",
    "        recall = tp / (tp + fn)\n",
    "    \"\"\"\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    tp = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    fn = np.array([len(x[0] - x[1]) for x in zip(y_true, y_pred)])\n",
    "    score = tp / (tp + fn)\n",
    "    return round(score.mean(), 4)\n",
    "\n",
    "def precision(y_true, y_pred) -> float:\n",
    "    \"\"\"\n",
    "    Actual positives among the model's positive predictions\n",
    "    Math:\n",
    "        precision = tp / (tp + fp)\n",
    "    \"\"\"\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    tp = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    fp = np.array([len(x[1] - x[0]) for x in zip(y_true, y_pred)])\n",
    "    score = tp / (tp + fp)\n",
    "    return round(score.mean(), 4)\n",
    "\n",
    "def f_beta(y_true, y_pred, beta: float = 1) -> float:\n",
    "    \"\"\"\n",
    "    F-beta score, in this competition, beta is 1 (micro f1 score)\n",
    "    Element Explanation:\n",
    "        tp: true positive\n",
    "        fp: false positive\n",
    "        tn: true negative\n",
    "        fn: false negative\n",
    "        if true ~, prediction == ground truth,\n",
    "        if false ~, prediction != ground truth, ~ is prediction not ground truth value\n",
    "    Math:\n",
    "        f_beta = (1 + beta ** 2) * precision * recall / (beta ** 2 * precision + recall)\n",
    "        if you want to emphasize precision, set beta < 1, options: 0.3, 0.6\n",
    "        if you want to emphasize recall, set beta > 1, options: 1.5, 2\n",
    "    Reference:\n",
    "        https://blog.naver.com/PostView.naver?blogId=wideeyed&logNo=221531998840&parentCategoryNo=&categoryNo=2&\n",
    "    \"\"\"\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    tp = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    fp = np.array([len(x[1] - x[0]) for x in zip(y_true, y_pred)])\n",
    "    fn = np.array([len(x[0] - x[1]) for x in zip(y_true, y_pred)])\n",
    "    f_precision = tp / (tp + fp)\n",
    "    f_recall = tp / (tp + fn)\n",
    "    score = (1 + beta ** 2) * f_precision * f_recall / (beta ** 2 * f_precision + f_recall)\n",
    "    return round(score.mean(), 4)\n",
    "\n",
    "def calc_overlap(row: pd.Series) -> list:\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and ground truth and overlap percentages\n",
    "    used for determining true positives for F1-Score, gt is abbreviation for ground truth\n",
    "    \"\"\"\n",
    "    set_pred = set(row.predictionstring_pred.split(' '))\n",
    "    set_gt = set(row.predictionstring_gt.split(' '))\n",
    "    # Length of each and intersection\n",
    "    len_gt = len(set_gt)\n",
    "    len_pred = len(set_pred)\n",
    "    inter = len(set_gt.intersection(set_pred))\n",
    "    overlap_1 = inter / len_gt  # Recall\n",
    "    overlap_2 = inter / len_pred  # Precision\n",
    "    return [overlap_1, overlap_2]\n",
    "\n",
    "\n",
    "def score_feedback_comp(pred_df: pd.DataFrame, gt_df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Function for scoring for competition\n",
    "    Step 1:\n",
    "        Make dataframe all ground truths and predictions for a given class are compared\n",
    "    Step 2:\n",
    "        If the overlap between the ground truth and prediction is >= 0.5 (Recall),\n",
    "        and the overlap between the prediction and the ground truth >= 0.5 (Precision),\n",
    "        In other words, prediction will be accepted 'True Positive',\n",
    "        when Precision & Recall greater than 0.5\n",
    "        the prediction is a match and considered a true positive.\n",
    "        If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "        And then count number of Potential True Positive ids\n",
    "    Step 3:\n",
    "        Any unmatched ground truths are false negatives and any unmatched predictions are false positives.\n",
    "        And then count number of Potential False Positives\n",
    "    Step 4.\n",
    "        Calculate Micro F1-Score for Cross Validation\n",
    "    Reference:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    gt_df = gt_df[['id', 'discourse_type', 'predictionstring']].reset_index(drop=True).copy()\n",
    "    pred_df = pred_df[['id', 'class', 'predictionstring']].reset_index(drop=True).copy()\n",
    "    pred_df['pred_id'] = pred_df.index\n",
    "    gt_df['gt_id'] = gt_df.index\n",
    "\n",
    "    # Stage 1. Make dataframe\n",
    "    joined = pred_df.merge(\n",
    "        gt_df,\n",
    "        left_on=['id', 'class'],\n",
    "        right_on=['id', 'discourse_type'],\n",
    "        how='outer',\n",
    "        suffixes=('_pred', '_gt')\n",
    "    )\n",
    "    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n",
    "    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n",
    "    joined['overlaps'] = joined.apply(calc_overlap, axis=1)  # Calculate Overlapped Percentage\n",
    "\n",
    "    # Stage 2. Calculate Potential True Positive\n",
    "    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n",
    "    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n",
    "\n",
    "    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)  # Precision & Recall\n",
    "    joined['max_overlap'] = joined[['overlap1', 'overlap2']].max(axis=1)\n",
    "    tp_pred_ids = joined.query('potential_TP') \\\n",
    "        .sort_values('max_overlap', ascending=False) \\\n",
    "        .groupby(['id', 'predictionstring_gt']).first()['pred_id'].values\n",
    "\n",
    "    # stage 3. Calculate Potential False Positive\n",
    "    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n",
    "\n",
    "    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n",
    "    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n",
    "\n",
    "    # Stage 4. Calculate Micro F1-Score for Cross Validation\n",
    "    tp = len(tp_pred_ids)\n",
    "    fp = len(fp_pred_ids)\n",
    "    fn = len(unmatched_gt_ids)\n",
    "    score = tp / (tp + 0.5 * (fp + fn))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9ce05f57-808b-4301-a9e6-87a4c0397d23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Debugging NERDataset '"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Debugging NERDataset \"\"\"\n",
    "# test_text = train_df.text[0]\n",
    "# test_token = ner_tokenizing(CFG, test_text)\n",
    "# word_ids, offset_to_wordidx, offsets = test_token.word_ids(), split_mapping(test_text), test_token['offset_mapping']\n",
    "# split_word_ids = np.full(len(word_ids), -1)\n",
    "\n",
    "# len(offset_to_wordidx), offset_to_wordidx, offsets\n",
    "# is_train = True \n",
    "# label_ids = []\n",
    "# word_labels = ast.literal_eval(train_df.entities[0])\n",
    "# for token_idx, word_idx in reversed(list(enumerate(word_ids))):\n",
    "#     if word_idx is None:\n",
    "#         \"\"\" for padding token \"\"\"\n",
    "#         if is_train:\n",
    "#             label_ids.append(-100)\n",
    "#     else:\n",
    "#         if offsets[token_idx] != (0, 0):\n",
    "#             # Choose the split word that shares the most characters with the token if any\n",
    "#             split_idxs = offset_to_wordidx[offsets[token_idx][0]:offsets[token_idx][1]]\n",
    "#             split_index = stats.mode(split_idxs[split_idxs != -1]).mode[0] if len(np.unique(split_idxs)) > 1 else split_idxs[0]\n",
    "#             if split_index != -1:\n",
    "#                 if is_train:\n",
    "#                     label_ids.append(labels2ids[word_labels[split_index]])\n",
    "#                 split_word_ids[token_idx] = split_index\n",
    "#             else:\n",
    "#                 # Even if we don't find a word, continue labeling 'I' tokens until a 'B' token is found\n",
    "#                 if label_ids and label_ids[-1] != -100 and ids2labels[label_ids[-1]][0] == 'I':\n",
    "#                     split_word_ids[token_idx] = split_word_ids[token_idx + 1]\n",
    "#                     if is_train:\n",
    "#                         label_ids.append(label_ids[-1])\n",
    "#                 else:\n",
    "#                     if is_train:\n",
    "#                         label_ids.append(-100)\n",
    "#         else:\n",
    "#             if is_train:\n",
    "#                 label_ids.append(-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7436b90c-a47b-495b-a1f6-de071d1a99d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Custom Dataset Class \"\"\"\n",
    "\n",
    "class NERDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset Class for NER Task\n",
    "    Args:\n",
    "        cfg: configuration.CFG\n",
    "        df: dataframe from .txt file\n",
    "        is_train: if this param set False, return word_ids from self.df.entities\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg: configuration.CFG, df: pd.DataFrame, is_train: bool = True) -> None:\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "        self.tokenizer = ner_tokenizing\n",
    "        self.labels2ids = labels2ids()  # Function for Encoding Labels to ids\n",
    "        self.ids2labels = ids2labels()  # Function for Decoding ids to Labels\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, item: int) -> dict[Tensor, Tensor, Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        1) Tokenizing input text:\n",
    "            - if you param 'return_offsets_mapping' == True, tokenizer doen't erase \\n or \\n\\n\n",
    "              but, I don't know this param also applying for DeBERTa Pretrained Tokenizer\n",
    "        2) Create targets and mapping of tokens to split() words by tokenizer\n",
    "            - Mapping Labels to split tokens\n",
    "            - Iterate in reverse to label whitespace tokens until a Begin token is encountered\n",
    "            - Tokenizer will split word into subsequent of character such as copied => copy, ##ed\n",
    "            - So, we need to find having same parent token and then label BIO NER Tags\n",
    "        3) Return dict:\n",
    "            - Train: dict.keys = [inputs_id, attention_mask, token_type_ids, labels]\n",
    "            - Validation/Test: dict.keys = [inputs_id, attention_mask, token_type_ids, word_ids]\n",
    "        \"\"\"\n",
    "        text = self.df.text[item]\n",
    "        if self.is_train:\n",
    "            word_labels = ast.literal_eval(self.df.entities[item])\n",
    "\n",
    "        # 1) Tokenizing input text\n",
    "        encoding = self.tokenizer(\n",
    "            self.cfg,\n",
    "            text,\n",
    "        )\n",
    "        word_ids = encoding.word_ids()\n",
    "        split_word_ids = np.full(len(word_ids), -1)\n",
    "        offset_to_wordidx = split_mapping(text)  # [1, sequence_length]\n",
    "        offsets = encoding['offset_mapping']  # [(src, end), (src, end), ...]\n",
    "\n",
    "        # 2) Find having same parent token and then label BIO NER Tags\n",
    "        label_ids = []\n",
    "        for token_idx, word_idx in reversed(list(enumerate(word_ids))):\n",
    "            if word_idx is None:\n",
    "                \"\"\" for padding token \"\"\"\n",
    "                if self.is_train:\n",
    "                    label_ids.append(-100)\n",
    "            else:\n",
    "                if offsets[token_idx] != (0, 0):\n",
    "                    # Choose the split word that shares the most characters with the token if any\n",
    "                    split_idxs = offset_to_wordidx[offsets[token_idx][0]:offsets[token_idx][1]]\n",
    "                    split_index = stats.mode(split_idxs[split_idxs != -1]).mode[0] if len(\n",
    "                        np.unique(split_idxs)) > 1 else split_idxs[0]\n",
    "                    if split_index != -1:\n",
    "                        if self.is_train:\n",
    "                            label_ids.append(labels2ids[word_labels[split_index]])\n",
    "                        split_word_ids[token_idx] = split_index\n",
    "                    else:\n",
    "                        # Even if we don't find a word, continue labeling 'I' tokens until a 'B' token is found\n",
    "                        if label_ids and label_ids[-1] != -100 and self.ids2labels[label_ids[-1]][0] == 'I':\n",
    "                            split_word_ids[token_idx] = split_word_ids[token_idx + 1]\n",
    "                            if self.is_train:\n",
    "                                label_ids.append(label_ids[-1])\n",
    "                        else:\n",
    "                            if self.is_train:\n",
    "                                label_ids.append(-100)\n",
    "                else:\n",
    "                    if self.is_train:\n",
    "                        label_ids.append(-100)\n",
    "        encoding['labels'] = list(reversed(label_ids))   # restore to original order\n",
    "        if not self.is_train:\n",
    "            encoding['word_ids'] = torch.as_tensor(split_word_ids)\n",
    "        else:\n",
    "            for k, v in encoding.items():\n",
    "                encoding[k] = torch.as_tensor(v)\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8422bc84-ce49-4775-8aca-f07f59f3eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Custom Model Class \"\"\"\n",
    "\n",
    "class NERModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Model class For NER Task Pipeline, in this class no pooling layer\n",
    "    This pipeline apply B.I.O Style, so the number of classes is 15 which is 7 unique classes original\n",
    "    Each of 7 unique classes has sub 2 classes (B, I) => 14 classes\n",
    "    And 1 class for O => 1 class\n",
    "    14 + 1 = 15 classes\n",
    "    Args:\n",
    "        cfg: configuration.CFG\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg: configuration.CFG) -> None:\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.auto_cfg = AutoConfig.from_pretrained(\n",
    "            cfg.model,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        self.model = AutoModel.from_pretrained(\n",
    "            cfg.model,\n",
    "            config=self.auto_cfg\n",
    "        )\n",
    "        self.fc = nn.Linear(self.auto_cfg.hidden_size, 15)  # BIO Style NER Task\n",
    "\n",
    "        if self.cfg.reinit:\n",
    "            self._init_weights(self.fc)\n",
    "            reinit_topk(self.model, cfg.num_reinit)\n",
    "\n",
    "        if self.cfg.freeze:\n",
    "            freeze(self.model.embeddings)\n",
    "            freeze(self.model.encoder.layer[:cfg.num_freeze])\n",
    "\n",
    "        if self.cfg.gradient_checkpoint:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "\n",
    "    def _init_weights(self, module) -> None:\n",
    "        \"\"\" over-ride initializes weights of the given module function (+initializes LayerNorm) \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if self.cfg.init_weight == 'normal':\n",
    "                module.weight.data.normal_(mean=0.0, std=self.auto_cfg.initializer_range)\n",
    "            elif self.cfg.init_weight == 'xavier_uniform':\n",
    "                module.weight.data = nn.init.xavier_uniform_(module.weight.data)\n",
    "            elif self.cfg.init_weight == 'xavier_normal':\n",
    "                module.weight.data = nn.init.xavier_normal_(module.weight.data)\n",
    "            elif self.cfg.init_weight == 'kaiming_uniform':\n",
    "                module.weight.data = nn.init.kaiming_uniform_(module.weight.data)\n",
    "            elif self.cfg.init_weight == 'kaiming_normal':\n",
    "                module.weight.data = nn.init.kaiming_normal_(module.weight.data)\n",
    "            elif self.cfg.init_weight == 'orthogonal':\n",
    "                module.weight.data = nn.init.orthogonal_(module.weight.data)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.auto_cfg.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            \"\"\" reference from torch.nn.Layernorm with elementwise_affine=True \"\"\"\n",
    "            module.weight.data.fill_(1.0)\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "    def feature(self, inputs: dict):\n",
    "        outputs = self.model(**inputs)\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, inputs: dict[Tensor, Tensor, Tensor]) -> Tensor:\n",
    "        \"\"\"\n",
    "        No Pooling Layer for word-level task\n",
    "        Args:\n",
    "            inputs: Dict type from AutoTokenizer\n",
    "            => {input_ids: Tensor[], attention_mask: Tensor[], token_type_ids: Tensor[]}\n",
    "        \"\"\"\n",
    "        outputs = self.feature(inputs)\n",
    "        logit = self.fc(outputs.last_hidden_state)\n",
    "        return logit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
